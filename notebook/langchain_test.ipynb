{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/code_Bao/stock_price_4_fun/notebook\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    print(file_path)\n",
    "except:\n",
    "    file_path = os.path.abspath('')\n",
    "    os.chdir(os.path.dirname(file_path))\n",
    "    print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import (\n",
    "    NewsURLLoader,\n",
    "    TrelloLoader,\n",
    ")\n",
    "from unstructured.cleaners.core import clean_extra_whitespace\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from src.Microsofttodo import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRELLO_API_KEY= os.getenv('TRELLO_API_KEY')\n",
    "TRELLO_TOKEN = os.getenv('TRELLO_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get the open cards from \"Awesome Board\"\n",
    "# loader = TrelloLoader.from_credentials(\n",
    "#     \"SOW data\",\n",
    "#     api_key=TRELLO_API_KEY,\n",
    "#     token=TRELLO_TOKEN,\n",
    "#     card_filter=\"open\",\n",
    "# )\n",
    "# documents = loader.load()\n",
    "\n",
    "# print(documents[0].page_content)\n",
    "# print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get all the cards from \"Awesome Board\" but only include the\n",
    "# # card list(column) as extra metadata.\n",
    "# loader = TrelloLoader.from_credentials(\n",
    "#     \"SOW data\",\n",
    "#     api_key=TRELLO_API_KEY,\n",
    "#     token=TRELLO_TOKEN,\n",
    "#     extra_metadata=(\"list\"),\n",
    "# )\n",
    "# documents = loader.load()\n",
    "\n",
    "# print(documents[0].page_content)\n",
    "# print(documents[0].metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo = MicrosoftToDo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Implement optuna', 'make docker for OCR', 'Check data grip about OPS. What else?', 'Reimplement scaffold prj', 'Lên plan đi đà lạt', 'Shopping', 'stock', 'Cloud computing Foundation']\n"
     ]
    }
   ],
   "source": [
    "todo_tasks = todo.get_tasks(list_name='Tasks')\n",
    "todo_tasks[0:2]\n",
    "names = [item['title'] for item in todo_tasks]\n",
    "print (names)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists:  ['Tasks', '2022', '2023', '2024', 'Giải quyết với Trân', 'LLM RAG and Notion', 'Mua sách', 'Telegram bot', 'Vietnamese stock forecast', 'Flagged Emails']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'@odata.etag': 'W/\"wyYSbsYOaUCZPsQATrx1BgAE5rPQOA==\"',\n",
       " 'displayName': 'Tasks',\n",
       " 'isOwner': True,\n",
       " 'isShared': False,\n",
       " 'wellknownListName': 'defaultList',\n",
       " 'id': 'AQMkADAwATMwMAItMTg4AGMtZmRiNC0wMAItMDAKAC4AAAORlXbjKGFLSJiBLf4_KVkjAQDDJhJuxg5pQJk_xABOvHUGAAACARIAAAA='}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo_lists = todo.get_lists()\n",
    "todo_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@odata.etag': 'W/\"wyYSbsYOaUCZPsQATrx1BgAE4T+1bQ==\"',\n",
       " 'displayName': '2022',\n",
       " 'isOwner': True,\n",
       " 'isShared': False,\n",
       " 'wellknownListName': 'none',\n",
       " 'id': 'AQMkADAwATMwMAItMTg4AGMtZmRiNC0wMAItMDAKAC4AAAORlXbjKGFLSJiBLf4_KVkjAQDDJhJuxg5pQJk_xABOvHUGAAMPg-liAAAA'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo_lists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_task(task_name='hello', list_name='Tasks', reminder_datetime=datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'importance': 'normal',\n",
       "  'isReminderOn': False,\n",
       "  'title': 'Implement optuna',\n",
       "  'createdDateTime': '2024-01-12T15:33:01.9531463Z',\n",
       "  'hasAttachments': False,\n",
       "  'checklistItems': None,\n",
       "  'body': {'content': '\\r\\n', 'contentType': 'text'}},\n",
       " {'importance': 'normal',\n",
       "  'isReminderOn': False,\n",
       "  'title': 'make docker for OCR',\n",
       "  'createdDateTime': '2024-01-10T01:16:31.0185463Z',\n",
       "  'hasAttachments': False,\n",
       "  'checklistItems': [{'displayName': 'fix code',\n",
       "    'createdDateTime': '2024-01-12T09:44:47.3570857Z',\n",
       "    'isChecked': False,\n",
       "    'id': '68ae218c-976b-4156-a2b2-446301c56aad'},\n",
       "   {'displayName': 'Fix error daemon',\n",
       "    'createdDateTime': '2024-01-12T09:44:55.8992274Z',\n",
       "    'checkedDateTime': '2024-01-12T09:44:57.4163443Z',\n",
       "    'isChecked': True,\n",
       "    'id': '7a39336f-54b5-45e3-b9ed-4a858c440aae'}],\n",
       "  'body': {'content': '', 'contentType': 'text'}}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todo_tasks = todo.get_short_form_tasks(list_name='Tasks', )\n",
    "todo_tasks[0:2]\n",
    "# names = [item['title'] for item in todo_tasks]\n",
    "# print (names)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo.create_task(task_name='hello2', list_name='Tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import CTransformers\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I have to go to the gym at 9, and figure out the power of 2, I have to call my parent at 6 in my house, and do my homework with james\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SeperateTaskPrompt:\n",
    "#     def __init__(self):\n",
    "#         self.template = \"\"\"Do not write irrelevant information. Seperate text into tasks. return a list of tasks\n",
    "#         For example:\n",
    "#         Input: \"I have to check out a Gemini bro and I have to go to shopping. I have to play Pemington tomorrow at 8 o'clock\"\n",
    "#         Output: [\"check out a Gemini bro\",\"go to shopping\"]\n",
    "#         Now separate this text = {question}\n",
    "#         Answer:\"\"\"\n",
    "#         self.llm = self.load_llm()\n",
    "#         self.prompt = PromptTemplate(template=self.template, input_variables=['question'])\n",
    "#         self.llm_chain = LLMChain(prompt=self.prompt, llm=self.llm)\n",
    "\n",
    "#     def load_llm(self):\n",
    "#         llm = CTransformers(\n",
    "#             model='TheBloke/Llama-2-7B-Chat-GGML', \n",
    "#             model_file='llama-2-7b-chat.ggmlv3.q4_1.bin',\n",
    "#             max_new_tokens=512,\n",
    "#             temperature=0.5,\n",
    "#             reset = True,\n",
    "#             seed = 42, \n",
    "#             # gpu_layers=500,\n",
    "#             )\n",
    "#         return llm\n",
    "    \n",
    "#     def get_response(self, text) -> list:\n",
    "#         response = self.llm_chain(text) #return dict of question and answer text\n",
    "#         response = self.get_tasks_from_string(text = response['text'])\n",
    "#         return response\n",
    "\n",
    "#     def get_tasks_from_string(self, text:str) -> list:\n",
    "#         # Find the substring between '[' and ']'\n",
    "#         start_index = text.find('[')\n",
    "#         end_index = text.find(']') + 1\n",
    "#         list_string = text[start_index:end_index]\n",
    "#         task_list = ast.literal_eval(list_string)\n",
    "#         return task_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperator = SeperateTaskPrompt()\n",
    "# list1 = seperator.get_response(text)\n",
    "# print(list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_llm():\n",
    "#     llm = CTransformers(\n",
    "#         model='TheBloke/Llama-2-7B-Chat-GGML', \n",
    "#         model_file='llama-2-7b-chat.ggmlv3.q4_1.bin',\n",
    "#         max_new_tokens=512,\n",
    "#         temperature=0.5,\n",
    "#         reset = True,\n",
    "#         seed = 42, \n",
    "#         )\n",
    "#     return llm\n",
    "# llm =load_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00be59111c3444bbd320f875bc8501d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c33a9aec4145bfab8378dd8595bdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "\n",
    "class CustomLLM(LLM):\n",
    "    model:Any\n",
    "    def __init__(self, model):\n",
    "      super().__init__()\n",
    "      self.model = model\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "       return \"custom\"\n",
    "    \n",
    "    def _call(self, prompt:str, stop:Optional[List[str]]=None, run_manager:Optional[CallbackManagerForLLMRun]=None,**kwargs: Any) -> str:\n",
    "        response = self.model(prompt)\n",
    "        return response[len(prompt):]\n",
    "    \n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying params\"\"\"\n",
    "        return {}\n",
    "\n",
    "\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "\n",
    "llm = AutoModelForCausalLM.from_pretrained(model_path_or_repo_id=\"TheBloke/Llama-2-7B-Chat-GGML\", \n",
    "                                           model_file='llama-2-7b-chat.ggmlv3.q4_1.bin', \n",
    "                                            max_new_tokens=512,\n",
    "                                            temperature=0.5,\n",
    "                                            reset = True,\n",
    "                                            seed = 42,\n",
    "                                            gpu_layers=50)\n",
    "\n",
    "llm = CustomLLM(model=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/code_Bao/stock_price_4_fun/venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Do not write irrelevant information. Seperate text into tasks. return a list of tasks\n",
    "For example:\n",
    "Input: \"I have to check out a Gemini bro and I have to go to shopping. I have to play Pemington tomorrow at 8 o'clock\"\n",
    "Output: [\"check out a Gemini bro\",\"go to shopping\"]\n",
    "Now separate this text = {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['question'])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "response = llm_chain(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 0)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/code_Bao/stock_price_4_fun/venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[29], line 11\u001b[0m\n    task_list = get_tasks_from_string(response['text'])\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[29], line 8\u001b[0m in \u001b[1;35mget_tasks_from_string\u001b[0m\n    task_list = ast.literal_eval(list_string)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/usr/lib/python3.10/ast.py:64\u001b[0m in \u001b[1;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/usr/lib/python3.10/ast.py:50\u001b[0;36m in \u001b[0;35mparse\u001b[0;36m\n\u001b[0;31m    return compile(source, filename, mode, flags,\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m<unknown>\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def get_tasks_from_string(input_string):\n",
    "    # Find the substring between '[' and ']'\n",
    "    start_index = input_string.find('[')\n",
    "    end_index = input_string.find(']') + 1\n",
    "    list_string = input_string[start_index:end_index]\n",
    "    task_list = ast.literal_eval(list_string)\n",
    "    return task_list\n",
    "\n",
    "task_list = get_tasks_from_string(response['text']) \n",
    "print(task_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
